{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec823f4c",
   "metadata": {},
   "source": [
    "# TypeScript로 시작하는 LangChain - 1. 입문  \n",
    "\n",
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de223df",
   "metadata": {},
   "source": [
    " <목차>\n",
    "\n",
    " 섹션 1. LLM(Large Language Model)\n",
    " - 1. LLM과 AI 방법론\n",
    " - 2. OpenAI API 활용\n",
    "\n",
    " 섹션 2. 프롬프트 엔지니어링\n",
    " - 1. OpenAI Playground\n",
    " - 2. 프롬프트 엔지니어링 기법\n",
    "\n",
    " 섹션 3. LangChain\n",
    " - 1. LLM과 LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de91fc26",
   "metadata": {},
   "source": [
    "## 프롬프트를 공부하는데 이런 내용들이 왜 필요한지?\n",
    " - LLM과 AI방법론을 알아야하는 이유\n",
    "   > 프롬프트는 LLM에게 \"어떻게 대답할지\" 지시하는 명령어다. \n",
    "\n",
    "   >어떤 모델이냐에 따라 동작이 달라지기 때문에 프롬프트를 효과적으로 쓰려면 모델의 특성을 이해해야한다.\n",
    "\n",
    " - OpenAI API를 알아야하는 이유\n",
    "   >실무에서는 API를 호출하기 때문에 API를 알아야 코드를 짤 수 있다.\n",
    "\n",
    "   >temperature, top_p, max_tokens 같은 파라미터도 함께 조절해야 효과적이므로 OpenAI API가 무엇인지 알아야한다.\n",
    "\n",
    " - LangChain을 알아야하는 이유\n",
    "   >LangChain을 알면 프롬프트의 '맥락'을 설계할 수 있다.\n",
    "\n",
    "   >단순한 질답을 넘어서 정보검색, 툴연동, 체인 구성 등을 가능하게하여 체계적으로 다루기 위해선 알아야하는 기술이다.\n",
    "\n",
    "\n",
    "* 즉, LLM 이해 + API 활용 + LangChain 구조화가 함께 가야 실전에서 잘 작동하는 “현실적인 AI 활용”이 된다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f49bb00",
   "metadata": {},
   "source": [
    "# 섹션 1. LLM (Large Language Model)\n",
    "\n",
    "1. LLM과 AI 방법론\n",
    "\n",
    "- LLM (대규모 언어 모델)\n",
    "\n",
    "  >대량의 텍스트 데이터를 기반으로 학습된 모델로, 자연어를 이해하고 생성하는 데 특화됨\n",
    "\n",
    "  >GPT, Claude, Gemini 등이 대표적\n",
    "\n",
    "- AI, ML, DL\n",
    "\n",
    "  >AI(Artificial Intelligence): 인간의 지능을 모방하는 기술 전반\n",
    "\n",
    "  >ML(Machine Learning, 머신러닝): 데이터로부터 학습하여 예측·판단하는 AI의 하위 분야\n",
    "\n",
    "  >DL(Deep Learning, 딥러닝): 인공신경망 기반의 복잡한 학습 방식. ML의 하위 분야\n",
    "\n",
    "- AI, ML, DL, LLM의 관계\n",
    "  >AI > ML > DL > LLM\n",
    "\n",
    "  >LLM은 딥러닝 중 특히 자연어 처리(NLP)를 위한 모델\n",
    "  \n",
    "  <img src=\"image-2.png\" alt=\"alt text\" style=\"width:40%;\">\n",
    "\n",
    "- 기타 AI 관련 용어 정리\n",
    "\n",
    "  >ANI(Artificial Narrow Intelligence) (약한 AI): 특정 작업만 수행 가능 (ex: ChatGPT)\n",
    "\n",
    "  >AGI(Artificial General Intelligence) (강한 AI): 인간 수준의 지능\n",
    "\n",
    "  >ASI(Artificial Super Intelligence) (초지능 AI): 인간 능력을 초월한 AI\n",
    "\n",
    "  >Generative AI: 텍스트, 이미지 등 창작 가능한 AI (LLM 포함)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5749c8f3",
   "metadata": {},
   "source": [
    "2. OpenAI API 활용\n",
    "- API Key 발급 절차\n",
    "\n",
    "    > OpenAI 회원가입 (https://openai.com/api/)→ API 키 생성 페이지 (api login>>dashboard>>API keys) → Key 생성 (Create new secret key)\n",
    "    * key는 이후에 다시 못보니 꼭 저장해둬야함!\n",
    "\n",
    "- API Key 관리\n",
    "\n",
    "    > .env 파일에 저장 (OPENAI_API_KEY=sk-...)  \n",
    "            $ .env.sample\n",
    "            OPENAI_API_KEY= replace_with_openai_key\n",
    "            -> replace_with_openai_key 위치에 본인이 발급 받은 값을 채워 넣으면 되도록 한다.\n",
    "\n",
    "    >  Git에 올리지 않도록 .gitignore 설정 필수  \n",
    "    * 유출 시 키 재발급 필요\n",
    "\n",
    "    > 키값을 GitHub 저장소에 push하면 어떤 문제가 발생하는지?  \n",
    "\n",
    "    > openAI API를 사용하다 보면 유료 사용량이 발생이 되는데, \n",
    "        퍼블릭 저장소에 내 API 키를 공개하게 되면 다른 사용자가 그 값을 활용해서 API를 호출하게 되고 \n",
    "        내 계정의 사용량으로 집계가 될 수 있는 문제가 생긴다.\n",
    "        그래서 .env 파일은 GitHub 저장소에 push가 안되게끔 gitignore에 등록하는 절차가 필요하다.\n",
    "\n",
    "- LLM 선택 기준\n",
    "\n",
    "    > 모델별 성능/비용/토큰 처리 능력 고려 (gpt-3.5 vs gpt-4 등)  \n",
    "\n",
    "    > Flagship model(대표모델)  \n",
    "        - GPT-4.5 Preview, GPT-4o, GPT-4o Audio  \n",
    "        Knowledge Cut-Off : 2023년 10월, 새로운 모델이 발표될 때마다 학습 데이터 범위 업데이트  \n",
    "    > Cust-optimized model (비용최적화 모델)  \n",
    "        - GPT-4o mini, GPT-4o mini Audio\n",
    "\n",
    "- Token 개념\n",
    "\n",
    "    > 텍스트의 최소 단위 (단어보다 작음)\n",
    "\n",
    "    > 요청 및 응답은 토큰 수에 따라 과금\n",
    "\n",
    "- LLM 사용 시 비용\n",
    "\n",
    "    > gpt-3.5: 저렴, 빠름 / gpt-4: 고성능, 고비용\n",
    "\n",
    "    > 실제 프로젝트에 맞춰 적절한 모델 선택  \n",
    "\n",
    "<br>   \n",
    "3. TypeScript가 실행가능한 환경 구성\n",
    "\n",
    "  1. tsx를 사용한다.https://tsx.is/getting-started  /  https://tsx.is/typescript 사이트에 들어가 설치 명령어들을 복사하여 실행해준다.\n",
    "        > Project installation : npm install -D tsx\n",
    "        \n",
    "        > TypeScript : npm install -D typescript @types/node\n",
    "        \n",
    "        > tsx실행 안될시, 글로벌 설치 : npm install -g tsx\n",
    "   \n",
    "  2. tsx로 파일을 실행할 수 있는지 확인한다.\n",
    "\t    > OpenAIChat.ts 파일을 만들고 consol.log를 작성 후, tsx OpenAIChat.ts 실행하여 실행결과를 확인한다.\n",
    "\t\n",
    "  3. 잘 실행이 됐다면 해당 파일에 env파일에서 관리하는 openAI 키 값을 불러오도록한다.  \n",
    "\t    > .env 모듈도 설치 필요 : npm install dotenv\n",
    "\t\n",
    "\t    > .env 파일을 만들고 OPENAI_API_KEY= replace_with_openai_key 작성.\n",
    "\t\n",
    "\t    > .env모듈을 사용하여 env파일의 값을 읽어올거기 때문에, OpenAIChat.ts 파일에 import문을 작성한다.\n",
    "\t\n",
    "\t    > OpenAI API 키 값으로 등록된 것을 상수에 할당한다.\n",
    "\n",
    "   \n",
    "  4. OpenAIChat.ts 파일에 import 및 객체생성\n",
    "\t    > openai 설치 필요 : npm install openai\n",
    "\t\n",
    "        > Openai 객체 생성  \n",
    "          - openai 객체를 만들때 API 키가 필요하다.\n",
    "\t \n",
    "        > chat.completions.create 함수를 호출하여 텍스트를 생성요청   \n",
    "          - 결과가 await로 응답이 도착되었을때 출력되게 한다.  \n",
    "          - 메세지 목록은 배열로 전달\n",
    "\t \n",
    "  5. consol.log를 작성 후, tsx OpenAIChat.ts 실행하여 실행결과를 확인한다.\n",
    "  \n",
    "  6. .env 파일은 GitHub 저장소에 push가 안되게끔 gitignore에 등록\n",
    "        > .gitignore 파일 생성\n",
    "\n",
    "<br> \n",
    "<br> \n",
    "openai 라이브러리 설치 후 API 호출 테스트 -> 01-OpenAIChat.ts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078f072e",
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "// import문을 추가하여 .env 모듈을 사용하여 env파일의 값을 읽어온다.\n",
    "import \"dotenv/config\"\n",
    "// OpenAI import\n",
    "import OpenAI from \"openai\"\n",
    "\n",
    "//OpenAI API 키 값으로 등록된 것을 상수에 할당한다.\n",
    "const { OPENAI_API_KEY } = process.env\n",
    "\n",
    "//openai 키 출력확인\n",
    "//console.log(OPENAI_API_KEY) //정상출력 확인.\n",
    "\n",
    "//Openai 객체 생성\n",
    "const openai = new OpenAI({\n",
    "    apiKey : OPENAI_API_KEY\n",
    "})\n",
    "\n",
    "// chat.completions.create 함수를 호출하여 텍스트를 생성요청 할 수 있다.\n",
    "// 결과가 await로 응답이 도착되었을때 출력되게 한다.\n",
    "// 메세지 목록은 배열로 전달\n",
    "const completions = await openai.chat.completions.create({\n",
    "    model: \"gpt-4o\",\n",
    "    messages: [\n",
    "        {role: \"system\", content: \"You are a helpful assistant.\"},\n",
    "        {\n",
    "            role: \"user\",\n",
    "            content: \"Please tell me the three most important things to keep in mind when talking to chatGPT.\"\n",
    "        }\n",
    "    ]\n",
    "})\n",
    "\n",
    "//completions 객체에서 필요한 결과만 꺼내오기 위해 choices 객체를 사용한다.\n",
    "console.log(completions.choices[0].message)\n",
    "\n",
    "//결과 : role이 Assistant, 즉 LLM이 생성한 결과라는 것. 그리고 인덱스 [0]에 해당하는 메시지 값이 출력된다.\n",
    "//근데 지금 나는 무료 티어라서... 안됨! RateLimitError : 요금제(quota)를 초과해서 발생하는 오류\n",
    "\n",
    "// C:\\vscode\\LANGCHAIN-TS>tsx OpenAIChat.ts\n",
    "// {\n",
    "// {\n",
    "// {\n",
    "//   role: 'assistant',\n",
    "//   content: 'When interacting with ChatGPT, here are three important things to keep in mind:\\n' +\n",
    "//     '\\n' +\n",
    "//     '1. **Clarity and Specificity**: To get the most useful responses, try to be as clear and specific as possible in your questions or prompts. Providing context and details helps the model understand your needs better and give more relevant answers.\\n' +\n",
    "//     '\\n' +\n",
    "//     \"2. **Limitations**: Remember that ChatGPT is a language model and has limitations. It may not have up-to-date information beyond its last training cut-off in October 2023, and it may not always understand nuanced real-world contexts or provide accurate answers to all questions. Additionally, it doesn't possess the ability to verify facts in real-time.\\n\" +\n",
    "//     '\\n' +\n",
    "//     \"3. **Security and Privacy**: Avoid sharing personal, sensitive, or confidential information during your interactions. While conversations with AI models are generally handled with privacy considerations in mind, it's good practice to exercise caution.\\n\" +\n",
    "//     '\\n' +\n",
    "//     'Being mindful of these aspects can enhance the quality of your interactions with ChatGPT.',\n",
    "//   refusal: null,\n",
    "//   annotations: []\n",
    "// }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7572d9",
   "metadata": {},
   "source": [
    "# 섹션 2. 프롬프트 엔지니어링\n",
    "\n",
    "1. OpenAI Playground\n",
    "- OpenAI Playground란?\n",
    "    > 프롬프트를 입력해 LLM 응답을 실험해볼 수 있는 웹 UI\n",
    "    > 다양한 파라미터를 직관적으로 조절 가능  \n",
    "    > https://platform.openai.com/playground/prompts\n",
    "\n",
    "    ![alt text](image-1.png)\n",
    "\n",
    "- 주요 파라미터\n",
    "\n",
    "    > Temperature: 창의성/일관성 정도를 조절 \n",
    "      * (0=일관성 ↑, 1=창의성 ↑)\n",
    "\n",
    "    > Max tokens: 응답 길이 제한, 즉 LLM모델이 생성할 수 있는 최대 토큰 수\n",
    "      * Token : 텍스트를 처리하느 청크(말뭉치)단위를 의미한다. 텍스트를 처리하는 그룹.\n",
    "\n",
    "    > Stop sequence: 모델의 토큰 생성을 중지시키는 문자열로 응답 중단 조건 설정하여, 모델 응답의 길이와 구조를 제어할 수 있다. \n",
    "\n",
    "    > Top P (nucleus sampling): 모델이 선택할 토큰의 다양성 정도를 설정.\n",
    "      * 값이 높을수록 다양한 답변 생성.\n",
    "\n",
    "</br>\n",
    " - LLM 활용시 주의해야할 부분은?\n",
    "\n",
    "1. 너무 광범위한 프롬프트는 예측 불가능한 결과 유발하기 때문에 적절한 범위 조절이 필요.\n",
    "2. 민감 정보, 사용자 프롬프트 유출 가능성 주의\n",
    "3. 사용자에게 응답을 전달하기 전에 한 번 더 검증하는 구현 절차가 들어가면 좋음.\n",
    "\n",
    "</br>\n",
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5cff27",
   "metadata": {},
   "source": [
    "2. 프롬프트 엔지니어링 기법\n",
    "\n",
    "- 프롬프트 엔지니어링이란?\n",
    "\n",
    "    >원하는 출력을 얻기 위해 LLM에게 효과적인 지시를 내리는 기술\n",
    "\n",
    "- 프롬프트 엔지니어링의 주요 기법\n",
    "    1. Zero-shot prompting: 설명만으로 문제 해결\n",
    "\n",
    "    2. Few-shot prompting: 모델이 응답을 생성할 때 참고할 수 있는 예시를 포함해 작업 요청\n",
    "\n",
    "    3. Chain-of-Thought prompting: 모델에게 \"생각의 흐름\"을 유도하여 단계적 사고를 하도록 설계\n",
    "\n",
    "- LLM 응답 비교하기\n",
    "\n",
    "    ** 예시 비교**\n",
    "    >모호한 프롬프트 : \"이 코드를 설명해줘.\"\n",
    "\n",
    "    >개선된 프롬프트 : \"이 Python코드의 핵심 로직이 무엇이고, 각 함수가 어떤 역할을 하는지 보안 전문가 입장해서 설명해줘.\"\n",
    "    * 위와 같이 질문의 질에 따라 응답 결과는 당연히 달라질 수 밖에 없다.\n",
    "\n",
    "- LLM 응답 결과를 개선할 수 있는 방법은?\n",
    "\n",
    "1. 프롬프트 엔지니어링\n",
    "    > 명확하고 구체적인 지시어 사용\n",
    "\n",
    "    > 역할 부여\n",
    "\n",
    "    > 필요한 배경 정보를 함께 제공하는 기대 출력 형식 제시\n",
    "\n",
    "    > 예시 포함\n",
    "    \n",
    "2. LLM 튜닝 및 보정\n",
    "    > RAG\n",
    "    >> LangChain, Llamalndex 등으로 구현\n",
    "\n",
    "    > 파인튜닝 : 특정 도메인에 맞는 텍스트로 추가 학습\n",
    "\n",
    "    > 프롬프트 템플릿 자동화 : 일관된 스타일 품질을 유지하기 위해 프롬프트 구조화화\n",
    "3. 후처리(Post-processing)\n",
    "    > 모델이 응답한 결과를 파싱하고, 불필요한 내용 제거, 형식 변환 등을 통해 개선 가능\n",
    "    >> JSON 출력 요구 후 검증 및 정제\n",
    "4. 사용자 피드백 반영\n",
    "    > 반복 사용 패턴을 분석하고, 어떤 응답이 만족스러웠는지 추적하여 개선\n",
    "\n",
    "    > LLM을 에이전트처럼 운영할 때 매우 중요하다.\n",
    "5. 멀티모달 / 다단계 질의의\n",
    "    > 하나의 거대한 질문보다는 작은 질문으로 나누고, 순차적으로 답변을 연결해 나가는 방식\n",
    "\n",
    "    > 텍스트 + 이미지/파일 입력을 함께 사용해 더 정밀한 질의 가능\n",
    "\n",
    "- 프롬프트 공유 사이트\n",
    "    > docs.anthropic.com  \n",
    "      - 프롬프트 라이브러리 페이지에서 주제에 따라 필터링하여 여러 프롬프트를 찾을 수 있다.  \n",
    "    > smith.langchain.com  \n",
    "      - Langchain Hub에서 여러 프롬프트를 찾을 수 있다.  \n",
    "      \n",
    "    > 그 밖의 공유사이트 : PromptHero, FlowGPT, PromptBase 등"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698472ca",
   "metadata": {},
   "source": [
    "# 섹션 3. LangChain\n",
    "1. LangChain 기술\n",
    "- LangChain이란?\n",
    "\n",
    "  >LLM을 체계적으로 구성하고 응용할 수 있도록 돕는 프레임워크\n",
    "\n",
    "  >다양한 컴포넌트 (프롬프트, 체인, 메모리, 에이전트 등) 제공하는 기술.\n",
    "\n",
    "  >사용자의 요청 즉, 프롬프트 구성하는 것도 LangChain에서 인터페이스가 잘 구축되어있고, LLM의 품질을 높이는데 도움이 되는 도구 활용 또한 잘 제공되고있다. \n",
    "이렇게 최종적으로 LLM이 응답을 생성하는 것까지 파이프라인이 LangChain을 통해서 구성하는데 편리한 측면이 있기 때문에 주목 받고 있는 기술이다.\n",
    "\n",
    "- LangChain의 특징\n",
    "\n",
    "| LangChain 0.3의 특징 \t\t\t\t|\n",
    "|-----------------------------------|\n",
    "| 1. 다양한 모델 통합   \t\t\t |\n",
    "| 2. 다양한 문서 포맷 로더 지원 \t |\n",
    "| 3. 프롬프트 관리      \t\t\t |\n",
    "| 4. 텍스트 분할        \t\t\t |\n",
    "| 5. 벡터스토어         \t\t\t |\n",
    "| 6. 다양한 도구 지원    \t\t\t |\n",
    "\n",
    "1. 현재(2025.03)는 0.3버전까지 업데이트가 되었고, Python, JavaScript를 공식적으로 지원.\n",
    "2. 문서와 저장소 모두 별도로 관리.\n",
    "\t> https://github.com/tmc/langchaingo \n",
    "\t> https://github.com/langchain-ai/langchainjs\n",
    "\t* GitHub - langChain / GitHub - langChainjs 개발을 할 때 필요한 정보들과 코드들을 확인할 수 있다.\n",
    "3. Providers (다양한 모델 통합)\n",
    "\t-LangChain은 여러 provider와 통합된 패키지를 지원한다.\n",
    "\t> https://python.langchain.com/docs/integrations/providers/\n",
    "\t> https://js.langchain.com/docs/integrations/platforms/\n",
    "4. Document Loaders를 지원한다. (다양한 문서 포맷 로더 지원)\n",
    "\t- 데이터를 LangChain Document 포멧으로 불러올 수 있도록 지원한다.\n",
    "\t> <2025.03 현재>  \n",
    "\t\t-\t1. web : 웹페이지 데이터 활용 (HTML 태그 파싱)  \n",
    "\t\t-\t2. local File : PDF,CSV,JSON 등의 문서 활용 (문서 구조를 유지하기 위한 추가 처리)  \n",
    "\t\t-\t3. Cloud : Cloud 데이터를 도큐먼트 타입으로 변환하여 활용 (Azure AI Data, Azure Blob Storage Container, AWS S3 Directory\n",
    "5. Vector stores (벡터스토어)\n",
    "\t-embedded 데이터를 저장하고 similarity search를 지원한다.\n",
    "\t* 임베디드 데이터 저장 : 데이터를 백터로 변환하여 저장,관리한다.\n",
    "\t* 시밀러리티 서치 : 사용자의 질문 또한 백터로 변환하여 백터간의 유사도를 계산하여 유사한 데이터가 검색되도록하는 기능.\n",
    "\t><2025.03 현재 백터스토어 종류>  \n",
    "\t>chroma - Embedding, vector search, document storage 등  \n",
    "\t>FAISS(Facebook AI Similarity Search - similarity search, vector clustering 등  \n",
    "\t>Pinecone - semantic / hybrid / Multi-modal search 등  \n",
    "\t>MongoDB Atlas - 클라우드 기반 관리형 DB + vector / full-text search 등\n",
    "\n",
    "</br>\n",
    "</br>\n",
    "- LLM 실행 실습 개요 (02-LangChainSimpleChat.ts) 아래 코드 참조.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecaf9ae",
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "\t//1. 라이브러리 설치 (Langchain 설치 / OpenAI 모듈 설치)\n",
    "\t// LangChain 기본 기능 활용 가능\n",
    "\t// 그 외 다른 모델, 데이터 저장 기능과 통합할 때는 별도의 라이브러리 추가 필요\n",
    "\t// 다른 패키지는 langchain-core 패키지에 의존한다.\n",
    "\t// >>  npm install langchain @langchain/core \n",
    "\t// >>  npm install @langchain/openai\n",
    "\n",
    "\t//2. OpenAI 패키지에서 모델에 요청을 할때 필요한 클래스를 import\n",
    "\t//  .env 모듈을 사용하여 환경변수(openai_api_key)를 불러올 수 있게 import\n",
    "\timport { ChatOpenAI } from \"@langchain/openai\"\n",
    "\timport { HumanMessage, SystemMessage } from \"@langchain/core/messages\"\n",
    "\timport \"dotenv/config\"\n",
    "\n",
    "\t//3. 사용하고자하는 모델객체를 생성한다.\n",
    "\tconst model = new ChatOpenAI({model:\"gpt-4o\"})\n",
    "\n",
    "\t//4. LLM에 전달할 메세지를 구성한다.\n",
    "\t//   LangChain에서는 메시지라는 타입이 정의가 되어있다.\n",
    "\t//   이전에 OpenAI API를 직접 호출할때는 role을 직접 타이핑했지만, Langchain을 사용하면 메시지 타입만을 이용해서 코딩가능.\n",
    "\t//   - SystemMessage : system role 메시지 \n",
    "\t//   - HumanMessage : user role 메시지\n",
    "\tconst messages = [\n",
    "\t\tnew SystemMessage(\"너는 사내 보안 교육 강사야. 직무별로 구체적인 사례를 1개씩 들고, 회사에 피해가 될 수 있는 행동을 유념할 수 있도록 설명해줘.\"),\n",
    "\t\tnew HumanMessage(\"LLM을 활용할 때 주의할 점을 알려줘.\")\n",
    "\t]\n",
    "\n",
    "\t//5. LLM의 결과를 answer 상수에 저장하고, 그중 content 내용만 출력하여 확인.\n",
    "\t// await : 응답이 도착되었을때 출력되게 함\n",
    "\t// invoke() :\n",
    "\tconst answer = await model.invoke(messages)\n",
    "\t// console.log(answer)\n",
    "\t//console.log(answer.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604f843c",
   "metadata": {},
   "source": [
    "- AI Message(assistant role의 메시지를 나타내는 클래스)에서 출력되는 다양한 데이터들 중 주요 키값들\n",
    "1. id : 메시지의 고유 식별자로써 사용이 된다.\n",
    "2. content : 응답 결과\n",
    "3. tool_calls : 메시지와 연관된 호출 가능한 tool\n",
    "4. usage_metadata : 토큰 수와 같은 메시지 사용량 데이터로, 비용으로 집계된다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
